{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaec7758",
   "metadata": {},
   "source": [
    "# Demo: Synthetic Data Generation and Streamlit Demo\n",
    "\n",
    "Bu notebook, veri üretimini ve basit bir Streamlit demo uygulamasını örnekler. Aşağıdaki bölümler kod odaklıdır: gereksinimler, rastgelelik kontrolü, temel dağılımlar, zaman serisi, görselleştirme ve küçük bir Prophet tahmin örneği.\n",
    "\n",
    "Not: Streamlit uygulamasını çalıştırmak için terminalde `streamlit run streamlit_app.py` komutunu kullanın."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb3b81",
   "metadata": {},
   "source": [
    "## 1) Gereksinimler ve ortam kurulumu\n",
    "Aşağıdaki paketleri kurun (örn. virtualenv içinde):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "# veya örnek olarak\n",
    "pip install numpy pandas matplotlib seaborn scikit-learn streamlit prophet plotly pytest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11db366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Rastgelelik ve tekrar üretilebilirlik (seed)\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "print('Seeds set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0447d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Temel dağılımlardan veri üretimi (Uniform, Normal, Poisson)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_norm = np.random.normal(loc=0, scale=1, size=1000)\n",
    "x_uniform = np.random.uniform(low=-1, high=1, size=1000)\n",
    "x_poisson = np.random.poisson(lam=3, size=1000)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,3))\n",
    "axs[0].hist(x_norm, bins=30); axs[0].set_title('Normal')\n",
    "axs[1].hist(x_uniform, bins=30); axs[1].set_title('Uniform')\n",
    "axs[2].hist(x_poisson, bins=30); axs[2].set_title('Poisson')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a25fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Çok değişkenli veri ve korelasyon (multivariate normal)\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "cov = [[1.0, 0.8, 0.3],[0.8, 1.0, 0.2],[0.3, 0.2, 1.0]]\n",
    "X = np.random.multivariate_normal(mean=[0,0,0], cov=cov, size=300)\n",
    "df_mv = pd.DataFrame(X, columns=['x1','x2','x3'])\n",
    "scatter_matrix(df_mv, alpha=0.6, figsize=(6,6));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab902619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Zaman serisi üretimi (trend, sezonsallık, AR(1))\n",
    "import pandas as pd\n",
    "\n",
    "def generate_ar1_series(phi=0.7, n=200, sigma=1.0, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    eps = np.random.normal(0, sigma, size=n)\n",
    "    x = np.zeros(n)\n",
    "    for t in range(1, n):\n",
    "        x[t] = phi * x[t-1] + eps[t]\n",
    "    return x\n",
    "\n",
    "n = 365\n",
    "trend = np.linspace(0, 10, n)\n",
    "season = 5 * np.sin(2 * np.pi * np.arange(n) / 365)\n",
    "ar = generate_ar1_series(phi=0.6, n=n, sigma=1.0, seed=1)\n",
    "series = trend + season + ar\n",
    "\n",
    "dates = pd.date_range('2023-01-01', periods=n)\n",
    "df_ts = pd.DataFrame({'Date': dates, 'Value': series})\n",
    "\n",
    "plt.figure(figsize=(10,3)); plt.plot(df_ts['Date'], df_ts['Value']); plt.title('Trend + Season + AR(1)'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Sınıflandırma ve regresyon için sentetik veri (sklearn)\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "Xc, yc = make_classification(n_samples=300, n_features=2, n_informative=2, n_redundant=0, random_state=0)\n",
    "Xr, yr = make_regression(n_samples=300, n_features=1, noise=10.0, random_state=0)\n",
    "\n",
    "plt.figure(figsize=(6,3)); plt.scatter(Xc[:,0], Xc[:,1], c=yc); plt.title('Classification sample'); plt.show()\n",
    "plt.figure(figsize=(6,3)); plt.scatter(Xr[:,0], yr); plt.title('Regression sample'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Gürültü, outlier ve eksik değer ekleme\n",
    "\n",
    "def add_noise(arr, scale=1.0, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return arr + rng.normal(0, scale, size=arr.shape)\n",
    "\n",
    "arr = np.linspace(0, 10, 100)\n",
    "arr_noisy = add_noise(arr, scale=0.5, seed=0)\n",
    "\n",
    "# Add outliers\n",
    "arr_noisy[::20] += 10\n",
    "\n",
    "# Add missing\n",
    "arr_noisy[5] = np.nan\n",
    "\n",
    "plt.figure(figsize=(6,3)); plt.plot(arr_noisy); plt.title('Noisy series with outliers and missing'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11033d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Veri kaydetme ve paylaşma (CSV, Parquet, np.save)\n",
    "# Örnek: df_ts to CSV / Parquet\n",
    "csv_path = 'data/processed/demo_time_series.csv'\n",
    "parquet_path = 'data/processed/demo_time_series.parquet'\n",
    "\n",
    "import os\n",
    "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "\n",
    "df_ts.to_csv(csv_path, index=False)\n",
    "df_ts.to_parquet(parquet_path)\n",
    "print('Saved CSV and Parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ce691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Görselleştirme (histogram, scatter, pairplot, zaman serisi)\n",
    "import plotly.express as px\n",
    "\n",
    "# Daily sales generator from project\n",
    "from data_generator import generate_fashion_data\n",
    "\n",
    "df = generate_fashion_data(output_path=None, periods=90, seed=0)\n",
    "\n",
    "# aggregate by date and product\n",
    "agg = df.groupby(['Date','Product'])['Sales'].sum().reset_index()\n",
    "fig = px.line(agg, x='Date', y='Sales', color='Product', title='Daily Sales by Product')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f80986",
   "metadata": {},
   "source": [
    "# 10) Streamlit demo uygulaması (parametre sliderları, görselleştirme, indirme)\n",
    "# Repo içinde `streamlit_app.py` dosyası bulunmaktadır. Streamlit uygulamasını terminalde aşağıdaki komut ile çalıştırabilirsiniz:\n",
    "# streamlit run streamlit_app.py\n",
    "\n",
    "print('Streamlit demo hazır: `streamlit_app.py` dosyasını kullanın')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62713b9c",
   "metadata": {},
   "source": [
    "## 11) Birim testler ve VSCode içinde çalışma (pytest)\n",
    "Test örnekleri projenin `tests/` klasöründe yer alır. `pytest` ile testleri çalıştırabilirsiniz."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
